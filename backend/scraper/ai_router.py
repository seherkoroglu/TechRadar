import openai
from fastapi import APIRouter, HTTPException, Request
from dotenv import load_dotenv
from typing import List, Optional
from openai import OpenAI
import os
from fastapi import APIRouter, Depends
import pandas as pd
import joblib
from pydantic import BaseModel
from typing import List
from serpapi import GoogleSearch
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import requests

router = APIRouter()  # âœ… BURASI ÅART

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()


serpapi_key = os.getenv("SERPAPI_KEY")

# âœ… OpenAI client oluÅŸtur
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# âœ… Yeni kayÄ±t bilgilerimizi destekleyecek model
class AIRequest(BaseModel):
    company: str
    website: Optional[str] = None
    description: Optional[str] = None
    sector: str
    subfields: List[str]


import os

BASE_DIR = os.path.dirname(os.path.realpath(__file__))  # scraper/ klasÃ¶rÃ¼nÃ¼n tam yolu

MODEL_PATH = os.path.join(BASE_DIR, "techcrunch_full_model.pkl")
VECTORIZER_PATH = os.path.join(BASE_DIR, "techcrunch_full_vectorizer.pkl")
NEWS_PATH = os.path.join(BASE_DIR, "techcrunch_full_news.csv")

model = joblib.load(MODEL_PATH)
vectorizer = joblib.load(VECTORIZER_PATH)
full_news_df = pd.read_csv(NEWS_PATH)

class TrendRequest(BaseModel):
    subfields: List[str]

@router.post("/suggestions")
def get_suggestions(data: AIRequest):
    company = data.company
    sector = data.sector
    website = data.website or "Bilinmiyor"
    description = data.description or ""
    subfields = ", ".join(data.subfields)

    prompt = (
        f"{company} adlÄ± ÅŸirket, {sector} sektÃ¶rÃ¼nde faaliyet gÃ¶stermektedir. Web sitesi: {website}. "
        f"Alt alanlar: {subfields}. AÃ§Ä±klama: {description}. "
        f"Bu ÅŸirkete Ã¶zel bÃ¼yÃ¼me stratejileri, inovasyon Ã¶nerileri ve rekabet avantajÄ± yaratacak kÄ±sa ve Ã¶z bilgiler sun."
        f" Rakip ÅŸirketleri gÃ¶ster ve onlar neler yapÄ±yor ayrÄ±ntÄ±lÄ± bahset."
    )

    try:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen strateji danÄ±ÅŸmanÄ± bir AI'sÄ±n."},
                {"role": "user", "content": prompt},
            ],
            max_tokens=900,
            temperature=0.9,
        )

        ai_response = completion.choices[0].message.content.strip()
        return {"suggestions": ai_response}

    except Exception as e:
        import traceback
        print("âŒ AI HATASI:", traceback.format_exc())
        raise HTTPException(status_code=500, detail="AI hatasÄ±: " + str(e))


@router.post("/forecast-advice")
async def get_forecast_advice(trend_comments: dict):
    try:
        comments = trend_comments.get("comments", [])
        if not comments:
            raise HTTPException(status_code=400, detail="Yorumlar boÅŸ.")

        trends_text = "\n".join([f"- {comment}" for comment in comments])

        prompt = f"""AÅŸaÄŸÄ±daki teknoloji trend analizlerine dayanarak teknoloji sektÃ¶rÃ¼nde Ã§alÄ±ÅŸan bir giriÅŸimci iÃ§in 3-4 cÃ¼mlelik profesyonel tavsiyeler hazÄ±rla:
{trends_text}

- Hangi alanlara yatÄ±rÄ±m yapÄ±lmalÄ±?
- Hangi alanlarda dikkatli olunmalÄ±?
- Potansiyel fÄ±rsatlar nerede olabilir?

CevabÄ±n kÄ±sa, net ve stratejik olsun."""

        # OpenAI 1.0.0 standardÄ±nda Chat oluÅŸturma
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "Sen deneyimli bir teknoloji danÄ±ÅŸmanÄ±sÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=1,
            max_tokens=700
        )

        advice = response.choices[0].message.content.strip()
        return {"status": "success", "advice": advice}

    except Exception as e:
        print(f"ğŸ”¥ OpenAI API HatasÄ±: {str(e)}")
        raise HTTPException(status_code=500, detail=f"OpenAI hatasÄ±: {str(e)}")


class Company(BaseModel):
    name: str
    description: str
    employees: str

class SectorRequest(BaseModel):
    sector: str
    companies: List[Company]


@router.post("/sector-analysis")
async def sector_analysis(request: SectorRequest):
    try:
        # Åirket aÃ§Ä±klamalarÄ±nÄ± birleÅŸtir
        combined_text = "\n".join([f"{c.name}: {c.description}" for c in request.companies])

        # Ä°yileÅŸtirilmiÅŸ prompt
        prompt = f"""
{request.sector} sektÃ¶rÃ¼nde faaliyet gÃ¶steren ÅŸirketlerin aÃ§Ä±klamalarÄ± ÅŸunlardÄ±r:\n{combined_text}\n
Bu aÃ§Ä±klamalara bakarak aÅŸaÄŸÄ±daki formatta Ã§ok kÄ±sa ve sade bir sektÃ¶rel analiz yaz:
- En fazla 5 madde olacak.
- Her madde 20 kelimeyi aÅŸmayacak.
- Madde madde yaz, baÅŸlÄ±klar kÄ±sa olsun.
- Uzun aÃ§Ä±klamalar yapma, sadece konu Ã¶zeti Ã§Ä±kar.
- BaÅŸlÄ±klarÄ±n altÄ±na 2-3 madde yaz.
- BaÅŸÄ±nda ve sonunda genel giriÅŸ-kapanÄ±ÅŸ cÃ¼mlesi olmasÄ±n.
- Sadece temiz, okunabilir maddeler Ã¼ret.
"""

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Sen sektÃ¶rel veri analisti bir asistansÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4
        )

        result = response.choices[0].message.content.strip()

        return {"status": "success", "analysis": result}

    except Exception as e:
        return {"status": "error", "message": str(e)}


@router.post("/ai/trend-prediction")
async def predict_trends(request: TrendRequest):
    try:
        subfield_keywords = [s.lower() for s in request.subfields]
        matched_news = []

        for _, row in full_news_df.iterrows():
            title = str(row["title"]).lower()
            if any(keyword in title for keyword in subfield_keywords):
                matched_news.append(title)

        if not matched_news:
            return {"status": "success", "trends": [], "message": "EÅŸleÅŸen haber bulunamadÄ±."}

        # Kategori tahmini yap
        X_vec = vectorizer.transform(matched_news)
        predictions = model.predict(X_vec)

        # Trendleri say
        trend_summary = {}
        for pred in predictions:
            trend_summary[pred] = trend_summary.get(pred, 0) + 1

        sorted_trends = sorted(
            ((str(k), int(v)) for k, v in trend_summary.items()),
            key=lambda x: x[1],
            reverse=True
        )

        # 2-3 kelimelik phrase extraction
        count_vect = CountVectorizer(ngram_range=(2, 3), stop_words='english')
        X_phrases = count_vect.fit_transform(matched_news)
        phrases = count_vect.get_feature_names_out()

        # Phrase frekanslarÄ±
        phrase_freq = X_phrases.sum(axis=0).A1
        phrase_freq_dict = dict(zip(phrases, phrase_freq))

        sorted_phrases = sorted(
            ((str(phrase), int(freq)) for phrase, freq in phrase_freq_dict.items()),
            key=lambda x: x[1],
            reverse=True
        )[:50]

        return {
            "status": "success",
            "trends": sorted_trends,
            "phrases": sorted_phrases
        }

    except Exception as e:
        return {"status": "error", "message": str(e)}

@router.post("/ai/trend-keywords")
async def trend_keywords(request: TrendRequest):
    try:
        subfield_keywords = [s.lower() for s in request.subfields]

        matched_titles = []
        for _, row in full_news_df.iterrows():
            title = str(row["title"]).lower()
            if any(keyword in title for keyword in subfield_keywords):
                matched_titles.append(title)

        if not matched_titles:
            return {"status": "success", "keywords": [], "message": "EÅŸleÅŸen haber bulunamadÄ±."}

        vectorizer = CountVectorizer(ngram_range=(2, 3), stop_words="english", max_features=100)
        X = vectorizer.fit_transform(matched_titles)
        keywords = vectorizer.get_feature_names_out()
        freqs = np.asarray(X.sum(axis=0)).flatten()

        keyword_freq_pairs = sorted(
            [(str(word), int(freq)) for word, freq in zip(keywords, freqs)],
            key=lambda x: x[1],
            reverse=True
        )

        return {"status": "success", "keywords": keyword_freq_pairs[:30]}

    except Exception as e:
        return {"status": "error", "message": str(e)}


class SubfieldRequest(BaseModel):
    subfield: str

@router.post("/ai/product-ideas")
async def generate_product_ideas(data: SubfieldRequest):
    subfield = data.subfield

    if not subfield:
        raise HTTPException(status_code=400, detail="Subfield bilgisi gerekli.")

    try:
        # 1. SerpApi ile subfield'a uygun ÅŸirket aramasÄ± yapalÄ±m
        search = GoogleSearch({
            "engine": "google",
            "q": f"{subfield} startups 2025",
            "api_key": serpapi_key,
            "num": 5
        })
        results = search.get_dict()

        companies = []
        for result in results.get("organic_results", []):
            title = result.get("title")
            snippet = result.get("snippet")
            if title and snippet:
                companies.append(f"{title}: {snippet}")

        if not companies:
            raise HTTPException(status_code=404, detail="Åirket bulunamadÄ±.")

        # 2. OpenAI ile Ã¼rÃ¼n fikirleri Ã¼rettirelim
        companies_text = "\n".join(companies)

        prompt = (
            f"KullanÄ±cÄ±nÄ±n sektÃ¶rÃ¼: {subfield}.\n"
            f"AÅŸaÄŸÄ±daki ÅŸirketler bu sektÃ¶rde faaliyet gÃ¶stermektedir:\n"
            f"{companies_text}\n\n"
            "Bu Ã¶rneklerden ilham alarak 5 yeni yaratÄ±cÄ± Ã¼rÃ¼n fikri Ã¼ret.\n"
            "Her bir fikri kÄ±sa ve Ã¶zgÃ¼n birer cÃ¼mle olarak numaralandÄ±r."
        )
        print("ğŸ“‹ Prompt:", prompt)

        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen yaratÄ±cÄ± bir Ã¼rÃ¼n geliÅŸtirme danÄ±ÅŸmanÄ±sÄ±n."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=800,
        )

        ai_response = completion.choices[0].message.content.strip()
        print("ğŸ§  OpenAI cevabÄ±:", ai_response)
        return {
            "companies": companies,
            "ideas": ai_response
        }

    except Exception as e:
        import traceback
        print("âŒ Hata:", traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/ai/trend-news")
def get_trend_news():
    API_KEY = "1b9cdfb7e9c34316847e7e085dabd303"  # ğŸ”¥
    url = f"https://newsapi.org/v2/top-headlines?category=technology&language=en&apiKey={API_KEY}"

    response = requests.get(url)
    if response.status_code != 200:
        return {"news": []}  # hata olursa boÅŸ dÃ¶nelim

    news_data = response.json()

    articles = news_data.get("articles", [])[:10]  # Ä°lk 10 haberi al
    result = [
        {
            "title": article.get("title", "BaÅŸlÄ±ksÄ±z"),
            "url": article.get("url", "#"),
            "publishedAt": article.get("publishedAt", "Bilinmiyor")
        }
        for article in articles
    ]
    return {"news": result}